{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72de0b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "from tkinter import *\n",
    "from PIL import ImageTk,Image\n",
    "import cv2\n",
    "import pyttsx3\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "880039c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_new_faces():\n",
    "    \n",
    "    text_speech = pyttsx3.init()\n",
    "    text_speech.setProperty(\"rate\",150)\n",
    "    text_speech.say(\"Store new faces\")\n",
    "    text_speech.runAndWait()\n",
    "     \n",
    "    def write():\n",
    "        global root2\n",
    "        a = entry1.get()\n",
    "        a = a.lower()\n",
    "        img_name = \"C:/Users/DELL/OneDrive/Desktop/Face directory/{}.png\".format(a)\n",
    "        cv2.imwrite(img_name,img)\n",
    "        \n",
    "        text_speech = pyttsx3.init()\n",
    "        text_speech.setProperty(\"rate\",150)\n",
    "        text_speech.say(\"Written\")\n",
    "        text_speech.runAndWait()\n",
    "                    \n",
    "        root2.destroy()\n",
    "        root.deiconify()\n",
    "        root1.deiconify()\n",
    "    \n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    voice_counter=1\n",
    "    cam_counter=1\n",
    "    \n",
    "    while True:\n",
    "        _,img = cap.read()\n",
    "\n",
    "        if not _:\n",
    "            print(\"failed to grab frame\")\n",
    "            break\n",
    "            \n",
    "        cv2.imshow('New face',img)\n",
    "        while cam_counter<2:\n",
    "            cv2.waitKey(1)\n",
    "            cam_counter+=1\n",
    "\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "        if len(faces) == 0:\n",
    "            print(\"face not detected\")\n",
    "            text_speech = pyttsx3.init()\n",
    "            text_speech.say(\"face not detected\")\n",
    "            text_speech.runAndWait()\n",
    "\n",
    "        elif len(faces) != 0:\n",
    "\n",
    "            for (x,y,w,h) in faces:\n",
    "                cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "            cv2.imshow('New face',img)\n",
    "\n",
    "            while voice_counter<2:\n",
    "                    print(\"Face detected, press space bar to store the face\")\n",
    "                    text_speech = pyttsx3.init()\n",
    "                    text_speech.setProperty(\"rate\",150)\n",
    "                    text_speech.say(\"Face detected, press space bar to store the face\")\n",
    "                    text_speech.runAndWait()\n",
    "                    voice_counter+=1\n",
    "\n",
    "\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k%256 == 32:\n",
    "            global entry1\n",
    "            global root2\n",
    "            root.withdraw()\n",
    "            root1.withdraw()\n",
    "            root2 = Toplevel()\n",
    "            root2.configure(bg = black)\n",
    "            root2.geometry(\"360x160\")\n",
    "            root2.iconbitmap('AI logo.ico')\n",
    "            root2.title(\"AI\")\n",
    "            root2.resizable(False,False)\n",
    "            \n",
    "            Label(root2, text = \"Enter name \",font = (\"Arial\",13,\"bold\"),fg = blue, bg = black).place(x = 30, y = 40)\n",
    "            entry1 = Entry(root2,font = (\"Arial\",13,\"bold\"))\n",
    "            entry1.place(x = 130,y = 40)\n",
    "            Button(root2,text = \"Enter\",font = (\"Arial\",13,\"bold\"),fg = \"black\",bg = \"white\",command = write).place(x = 120, y = 80)\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "143ad46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recognition():\n",
    "    \n",
    "    import face_recognition\n",
    "    import cv2\n",
    "\n",
    "    path = r\"C:\\Users\\DELL\\OneDrive\\Desktop\\Face directory\"\n",
    "    path1 = r\"C:\\Users\\DELL\\OneDrive\\Desktop\\Criminal directory\"\n",
    "    \n",
    "    text_speech = pyttsx3.init()\n",
    "    text_speech.setProperty(\"rate\",150)\n",
    "    text_speech.say(\"Face recognition\")\n",
    "    text_speech.runAndWait()\n",
    "\n",
    "    images = []\n",
    "    classnames = []\n",
    "    mylist = os.listdir(path)\n",
    "\n",
    "    for cl in mylist:\n",
    "        curimg = cv2.imread(f'{path}/{cl}')\n",
    "        images.append(curimg)\n",
    "        classnames.append(os.path.splitext(cl)[0])\n",
    "\n",
    "    images1 = []\n",
    "    classnames1 = []\n",
    "    mylist1 = os.listdir(path1)\n",
    "\n",
    "    for cl in mylist1:\n",
    "        curimg = cv2.imread(f'{path1}/{cl}')\n",
    "        images1.append(curimg)\n",
    "        classnames1.append(os.path.splitext(cl)[0])\n",
    "        \n",
    "    text_speech = pyttsx3.init()\n",
    "    text_speech.say(\"Please wait for a while\")\n",
    "    text_speech.runAndWait()\n",
    "            \n",
    "    def findencodings(images):\n",
    "        encodelist = []\n",
    "        for img in images:\n",
    "            img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "            encode = face_recognition.face_encodings(img)[0]\n",
    "            encodelist.append(encode)\n",
    "        return encodelist\n",
    "\n",
    "    encodelistknown = findencodings(images) \n",
    "    encodelistknown1 = findencodings(images1)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cam_counter = 1\n",
    "    voice_counter = 1\n",
    "\n",
    "    while True:\n",
    "\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k%256 == 32:\n",
    "            text_speech = pyttsx3.init()\n",
    "            text_speech.setProperty(\"rate\",160)\n",
    "            \n",
    "            if name.lower() in classnames1:\n",
    "                print(name+\" be cautious\")\n",
    "                text_speech.say(\"I can see \"+name.lower()+\" Be cautious\")\n",
    "                text_speech.runAndWait()\n",
    "                break\n",
    "            \n",
    "            elif name.lower() in classnames:\n",
    "                print(name)\n",
    "                text_speech.say(\"I can see \"+name.lower())\n",
    "                text_speech.runAndWait()\n",
    "                break\n",
    "                \n",
    "            else:\n",
    "                text_speech.say(\"No known face detected\")\n",
    "                text_speech.runAndWait()\n",
    "                break\n",
    "                \n",
    "            \n",
    "\n",
    "        success,img = cap.read()\n",
    "        imgs = cv2.resize(img,(0,0),None,0.25,0.25)\n",
    "        imgs = cv2.cvtColor(imgs,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        facescurframe = face_recognition.face_locations(imgs)\n",
    "        encodescurframe = face_recognition.face_encodings(imgs,facescurframe)\n",
    "        \n",
    "        if len(facescurframe) == 0:\n",
    "            text_speech = pyttsx3.init()\n",
    "            text_speech.say(\"No face detected\")\n",
    "            text_speech.runAndWait()\n",
    "            \n",
    "        else:\n",
    "\n",
    "            for encodeface,faceloc in zip(encodescurframe,facescurframe):\n",
    "                matches = face_recognition.compare_faces(encodelistknown,encodeface)\n",
    "                facedis = face_recognition.face_distance(encodelistknown,encodeface)\n",
    "                matchindex = np.argmin(facedis)\n",
    "\n",
    "                matches1 = face_recognition.compare_faces(encodelistknown1,encodeface)\n",
    "                facedis1 = face_recognition.face_distance(encodelistknown1,encodeface)\n",
    "                matchindex1 = np.argmin(facedis1)\n",
    "\n",
    "                if matches1[matchindex1]:\n",
    "                    name = classnames1[matchindex1].upper()\n",
    "                \n",
    "                elif matches[matchindex]:\n",
    "                    name = classnames[matchindex].upper()\n",
    "\n",
    "                else:\n",
    "                    name = \"UNKNOWN\"\n",
    "\n",
    "                y1,x2,y2,x1 = faceloc\n",
    "                y1,x2,y2,x1 = y1*4,x2*4,y2*4,x1*4\n",
    "                cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "                cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)\n",
    "                cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
    "                \n",
    "        cv2.imshow('webcam',img)\n",
    "        while cam_counter<2:\n",
    "                cv2.waitKey(1)\n",
    "                cam_counter+=1\n",
    "        while(voice_counter<2):\n",
    "            text_speech = pyttsx3.init()\n",
    "            text_speech.setProperty(\"rate\",190)\n",
    "            text_speech.say(\"Press space bar to know the person\")\n",
    "            text_speech.runAndWait()\n",
    "            voice_counter+=1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f72828bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criminal_detection():\n",
    "    \n",
    "    text_speech = pyttsx3.init()\n",
    "    text_speech.setProperty(\"rate\",150)\n",
    "    text_speech.say(\"Criminal directory\")\n",
    "    text_speech.runAndWait()\n",
    "    \n",
    "    def write():\n",
    "        global root3\n",
    "        a = entry2.get()\n",
    "        a = a.lower()\n",
    "        img_name = \"C:/Users/DELL/OneDrive/Desktop/Criminal directory/{}.png\".format(a)\n",
    "        cv2.imwrite(img_name,img)\n",
    "        text_speech = pyttsx3.init()\n",
    "        text_speech.setProperty(\"rate\",150)\n",
    "        text_speech.say(\"Written\")\n",
    "        text_speech.runAndWait()\n",
    "        root3.destroy()\n",
    "        root.deiconify()\n",
    "        root1.deiconify()\n",
    "    \n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    voice_counter=1\n",
    "    cam_counter=1\n",
    "    \n",
    "    while True:\n",
    "        _,img = cap.read()\n",
    "\n",
    "        if not _:\n",
    "            print(\"failed to grab frame\")\n",
    "            break\n",
    "            \n",
    "        cv2.imshow('New face',img)\n",
    "        while cam_counter<2:\n",
    "            cv2.waitKey(1)\n",
    "            cam_counter+=1\n",
    "\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "        if len(faces) == 0:\n",
    "            print(\"face not detected\")\n",
    "            text_speech = pyttsx3.init()\n",
    "            text_speech.say(\"face not detected\")\n",
    "            text_speech.runAndWait()\n",
    "\n",
    "        elif len(faces) != 0:\n",
    "\n",
    "            for (x,y,w,h) in faces:\n",
    "                cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "            cv2.imshow('New face',img)\n",
    "\n",
    "            while voice_counter<2:\n",
    "                    print(\"Face detected, press space bar to store into criminal directory\")\n",
    "                    text_speech = pyttsx3.init()\n",
    "                    text_speech.setProperty(\"rate\",150)\n",
    "                    text_speech.say(\"Face detected, press space bar to store into criminal directory\")\n",
    "                    text_speech.runAndWait()\n",
    "                    voice_counter+=1\n",
    "\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k%256 == 32:\n",
    "            global entry2\n",
    "            global root3\n",
    "            root.withdraw()\n",
    "            root1.withdraw()\n",
    "            root3 = Toplevel()\n",
    "            root3.configure(bg = black)\n",
    "            root3.geometry(\"360x160\")\n",
    "            root3.iconbitmap('AI logo.ico')\n",
    "            root3.title(\"AI\")\n",
    "            root3.resizable(False,False)\n",
    "            \n",
    "            Label(root3, text = \"Enter name \",font = (\"Arial\",13,\"bold\"),fg = blue, bg = black).place(x = 30, y = 40)\n",
    "            entry2 = Entry(root3,font = (\"Arial\",13,\"bold\"))\n",
    "            entry2.place(x = 130,y = 40)\n",
    "            Button(root3,text = \"Enter\",font = (\"Arial\",13,\"bold\"),fg = \"black\",bg = \"white\",command = write).place(x = 120, y = 80)\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e20b837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def know_the_emotion():\n",
    "    \n",
    "    text_speech = pyttsx3.init()\n",
    "    text_speech.setProperty(\"rate\",150)\n",
    "    text_speech.say(\"Emotion detection\")\n",
    "    text_speech.runAndWait()\n",
    "\n",
    "    voice_counter=1\n",
    "\n",
    "    while voice_counter<2:\n",
    "        text_speech = pyttsx3.init()\n",
    "        text_speech.say(\"Please wait\")\n",
    "        text_speech.runAndWait()\n",
    "        voice_counter+=1\n",
    "\n",
    "    face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    classifier =load_model(\"model.h5\")\n",
    "\n",
    "    emotion_labels = ['Angry','Disgust','Fear','Happy','Neutral', 'Sad', 'Surprise']\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    speech_counter=1\n",
    "    cam_counter=1\n",
    "\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        labels = []\n",
    "        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_classifier.detectMultiScale(gray)\n",
    "        \n",
    "        \n",
    "        k = cv2.waitKey(1)\n",
    "        if k%256 == 32:\n",
    "            text_speech = pyttsx3.init()\n",
    "            text_speech.setProperty(\"rate\",150)\n",
    "            text_speech.say(\"This person has \"+label+\" emotion\")\n",
    "            text_speech.runAndWait()\n",
    "            break\n",
    "\n",
    "        if len(faces) == 0:\n",
    "            text_speech = pyttsx3.init()\n",
    "            text_speech.setProperty(\"rate\",150)\n",
    "            text_speech.say(\"No face detected\")\n",
    "            text_speech.runAndWait()\n",
    "\n",
    "        else:\n",
    "            for (x,y,w,h) in faces:\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "                roi_gray = gray[y:y+h,x:x+w]\n",
    "                roi_gray = cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                while speech_counter<2:\n",
    "                    text_speech = pyttsx3.init()\n",
    "                    text_speech.setProperty(\"rate\",150)\n",
    "                    text_speech.say(\"Enter space to know the emotion\")\n",
    "                    text_speech.runAndWait()\n",
    "                    speech_counter+=1\n",
    "\n",
    "                if np.sum([roi_gray])!=0:\n",
    "                    roi = roi_gray.astype('float')/255.0\n",
    "                    roi = img_to_array(roi)\n",
    "                    roi = np.expand_dims(roi,axis=0)\n",
    "\n",
    "                    prediction = classifier.predict(roi)[0]\n",
    "                    label=emotion_labels[prediction.argmax()]\n",
    "                    label_position = (x,y)\n",
    "                    cv2.putText(frame,label,label_position,cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "\n",
    "\n",
    "        cv2.imshow('Emotion Detector',frame)\n",
    "        while cam_counter<2:\n",
    "                cv2.waitKey(1)\n",
    "                cam_counter+=1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69b03cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_recognition():\n",
    "    \n",
    "    text_speech = pyttsx3.init()\n",
    "    text_speech.setProperty(\"rate\",150)\n",
    "    text_speech.say(\"Text recognition\")\n",
    "    text_speech.runAndWait()\n",
    "\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    voice_counter=1\n",
    "    speech_counter=1\n",
    "    cam_counter=1\n",
    "    \n",
    "    while True:\n",
    "        ret,frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"failed to grab the frame\")\n",
    "            break\n",
    "\n",
    "        cv2.imshow(\"text\",frame)\n",
    "        while cam_counter<2:\n",
    "                cv2.waitKey(1)\n",
    "                cam_counter+=1\n",
    "\n",
    "        while voice_counter<2:\n",
    "            text_speech = pyttsx3.init()\n",
    "            text_speech.say(\"place the text and press space bar to read\")\n",
    "            text_speech.runAndWait()\n",
    "            voice_counter+=1\n",
    "\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k%256 == 32:\n",
    "            img_name = \"test.png\"\n",
    "            cv2.imwrite(img_name,frame)\n",
    "            \n",
    "            while speech_counter<2:\n",
    "                text_speech = pyttsx3.init()\n",
    "                text_speech.say(\"Recognition in process\")\n",
    "                text_speech.runAndWait()\n",
    "                speech_counter+=1\n",
    "                \n",
    "            pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract.exe'\n",
    "            tessdata_dir_config = '--tessdata-dir \"C:/Program Files/Tesseract-OCR/tessdata\"'\n",
    "            img = Image.open(\"test.png\")\n",
    "            text = pytesseract.image_to_string(img,config = tessdata_dir_config)\n",
    "            print(text)\n",
    "            if len(text) == 0:\n",
    "                text_speech = pyttsx3.init()\n",
    "                text_speech.setProperty(\"rate\",150)\n",
    "                text_speech.say(\"No text detected\")\n",
    "                text_speech.runAndWait()\n",
    "                \n",
    "            else:\n",
    "                text_speech = pyttsx3.init()\n",
    "                text_speech.say(text)\n",
    "                text_speech.runAndWait()    \n",
    "            os.remove(\"test.png\")\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e996660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detected, press space bar to store the face\n",
      "face not detected\n",
      "face not detected\n",
      "face not detected\n",
      "ANANYA\n",
      "Face detected, press space bar to store into criminal directory\n",
      "ANANYA be cautious\n",
      "They said, don’t give up on your dreams, So, | went back to.\n",
      "sleep\n",
      "\n",
      "Cut the trees, make paper with them and write “Save the\n",
      "trees”.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "root = Tk()\n",
    "home = PhotoImage(master = root,file =\"AI home.png\")\n",
    "label = Label(root,image = home)\n",
    "label.place(x = 0,y=0,relwidth = 1,relheight=1)\n",
    "root.geometry(\"476x549\")\n",
    "root.iconbitmap('AI logo.ico')\n",
    "root.title(\"AI\")\n",
    "\n",
    "blue = \"#A2D2FA\"\n",
    "black = \"#221F21\"\n",
    "\n",
    "root.configure(bg = black)\n",
    "root.resizable(False,False)\n",
    "\n",
    "def explore():\n",
    "    \n",
    "        global root1    \n",
    "        root1 = Toplevel()\n",
    "        image1 = Image.open(\"AI about.png\")\n",
    "        back_ground = ImageTk.PhotoImage(image1)\n",
    "        root1.geometry(\"550x778\")\n",
    "        root1.configure(bg = black)\n",
    "        root1.iconbitmap('AI logo.ico')\n",
    "        root1.title('AI')\n",
    "        root1.resizable(False,False)\n",
    "        \n",
    "        lbl = Label(root1,image = back_ground)\n",
    "        lbl.place(x=0,y=0)\n",
    "        b1= Button(root1,text = \"Use >\",font = (\"Open Sans\",14,\"bold\"),bg = black,fg = blue,width =6,command = input_new_faces).place(x=172,y=112)\n",
    "        b2= Button(root1,text = \"Use >\",font = (\"Open Sans\",14,\"bold\"),bg = black,fg = blue,width =6,command = face_recognition).place(x=320,y=272)\n",
    "        b3= Button(root1,text = \"Use >\",font = (\"Open Sans\",14,\"bold\"),bg = black,fg = blue,width =6,command = criminal_detection).place(x=172,y=430)\n",
    "        b4= Button(root1,text = \"Use >\",font = (\"Open Sans\",14,\"bold\"),bg = black,fg = blue,width =6,command = know_the_emotion).place(x=320,y=572)\n",
    "        b5= Button(root1,text = \"Use >\",font = (\"Open Sans\",14,\"bold\"),bg = black,fg = blue,width =6,command = text_recognition).place(x=177,y=717)\n",
    "\n",
    "        root1.mainloop()\n",
    "        \n",
    "\n",
    "b = Button(root,text = \"Explore >\",font = (\"Open Sans\",20,\"bold\"),width =10,bg = \"white\",fg = \"black\",command = explore).place(x=100,y=255)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4729772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
